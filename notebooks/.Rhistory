r12_before <- r12 %>% ggplot(aes(x=meanF_REP1,meanF_REP2_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r12$meanF_REP1, meanF_REP2_c = spline_r12$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 2")
r12_after <- r12 %>% ggplot(aes(x=meanF_REP1,meanF_REP2_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r12_before + r12_after
# Add the difference to the original values of the second replicate to obtain the corrected values:
r12$meanF_REP2_c <- r12$meanF_REP2 + diff
print("REPS: 1 and 2")
print(paste("Correlation before correction:", cor(r12$meanF_REP2,r12$meanF_REP1)))
print(paste("Correlation after correction:", cor(r12$meanF_REP1,r12$meanF_REP2_c))) # correlation of corrected values
print(paste("Correlation of the 'active' region:", cor(r12[r12$avg_meanF>=-4,]$meanF_REP1,r12[r12$avg_meanF>=-4,]$meanF_REP2_c))) # correlation of the "active" variants
# plot results:
r12_before <- r12 %>% ggplot(aes(x=meanF_REP1,meanF_REP2_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r12$meanF_REP1, meanF_REP2_c = spline_r12$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 2")
r12_after <- r12 %>% ggplot(aes(x=meanF_REP1,meanF_REP2_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r12_before + r12_after
# plot results:
r12_before <- r12 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP2)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r12$meanF_REP1, meanF_REP2_c = spline_r12$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 2")
r12_before + r12_after
r12
# plot results:
r12_before <- r12 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP2)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep2") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r12$meanF_REP1, meanF_REP2 = spline_r12$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 2")
r12_before + r12_after
knots_r13 <- summary(r13$meanF_REP1)[3] #using the median meanF of rep1 as internal knot
bound_knots_r13 <- c(min(c(r13$meanF_REP1,r13$meanF_REP3)), max(c(r13$meanF_REP1,r13$meanF_REP3))) # boundary knots
degree <- 2 # degree of piecewise polynomials
basis_mat <- iSpline(r13$meanF_REP1, knots = knots_r13, Boundary.knots = bound_knots_r13, degree = degree)
spline_r13 <- lm(r13$meanF_REP3 ~ basis_mat)
predicted_values <- predict(spline_r13, newdata=data.frame(r13$meanF_REP1))
diff <- r13$meanF_REP1 - predicted_values
r13$meanF_REP3_c <- r13$meanF_REP3 + diff
print("REPS: 1 and 3")
print(paste("Correlation before correction:", cor(r13$meanF_REP1,r13$meanF_REP3)))
print(paste("Correlation after correction:", cor(r13$meanF_REP1,r13$meanF_REP3_c))) # correlation of corrected values
print(paste("Correlation of the 'active' region:", cor(r13[r13$avg_meanF>=-4,]$meanF_REP1,r13[r13$avg_meanF>=-4,]$meanF_REP3_c))) # correlation of the "active" variants
# plot results:
r13_before <- r13 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP3)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep3") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r12$meanF_REP1, meanF_REP3 = spline_r13$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 3")
r13_after <- r13 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP3_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep3") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r13_before + r13_after
# plot results:
r13_before <- r13 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP3)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep3") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r13$meanF_REP1, meanF_REP3 = spline_r13$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 3")
r13_after <- r13 %>% ggplot(aes(x=meanF_REP1,y=meanF_REP3_c)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep3") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r13_before + r13_after
r14 %>% ggplot(aes(x=meanF_REP1,meanF_REP4)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep4") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r14 <- rbind(r14,r14_ctls)
r14 %>% ggplot(aes(x=meanF_REP1,meanF_REP4)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep4") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
knots_r14 <- summary(r14$meanF_REP1)[3] #using the median meanF of rep1 as internal knot
bound_knots_r14 <- c(min(c(r14$meanF_REP1,r14$meanF_REP4)), max(c(r14$meanF_REP1,r14$meanF_REP4))) # boundary knots
degree <- 2 # degree of piecewise polynomials
basis_mat <- iSpline(r14$meanF_REP1, knots = knots_r14, Boundary.knots = bound_knots_r14, degree = degree)
spline_r14 <- lm(r14$meanF_REP4 ~ basis_mat)
predicted_values <- predict(spline_r14, newdata=data.frame(r14$meanF_REP1))
diff <- r14$meanF_REP1 - predicted_values
r14$meanF_REP4_c <- r14$meanF_REP4 + diff
print("REPS: 1 and 3")
print(paste("Correlation before correction:", cor(r14$meanF_REP1,r14$meanF_REP4)))
print(paste("Correlation after correction:", cor(r14$meanF_REP1,r14$meanF_REP4_c))) # correlation of corrected values
print(paste("Correlation of the 'active' region:", cor(r14[r14$avg_meanF>=-4,]$meanF_REP1,r14[r14$avg_meanF>=-4,]$meanF_REP4_c))) # correlation of the "active" variants
# plot results:
r14_before <- r14 %>% ggplot(aes(x=meanF_REP1,meanF_REP4)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep4") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none") +
geom_line(data=data.frame(meanF_REP1 = r14$meanF_REP1, meanF_REP4 = spline_r14$fitted.values), size=1.3,col="red") + ggtitle("Reps 1 and 4")
r14_after <- r14 %>% ggplot(aes(x=meanF_REP1,meanF_REP4)) + stat_bin2d(bins = 100) + theme_classic() +
xlab("meanF, rep1") + ylab("meanF, rep4") + geom_abline(intercept = 0, slope = 1,col="gray") + theme(legend.position = "none")
r14_before + r14_after
REs <- list()
REs[[1]] <- factor(c("SRE1 (AA)", "SRE2 (GA)", "ERE (GT)", "AC",
"AG", "AT", "CA", "CC",
"CG", "CT", "GC", "GG",
"TA", "TC", "TG", "TT"),
levels=c("ERE (GT)", "SRE1 (AA)", "SRE2 (GA)", "AC",
"AG", "AT", "CA", "CC",
"CG", "CT","GC", "GG",
"TA", "TC", "TG", "TT"))
# convert REBC (RE barcode) to RE variant
REBC_to_RE <- function(REBC, levels=1) {
if(is.character(REBC)) {
bc <- str_extract(REBC, "\\d+")
bc <- as.integer(bc)
}
RE <- REs[[levels]][bc]
return(RE)
}
getwd()
setwd("/Users/santiagoherrera/Desktop/UChicago/Thornton_LAB/RH-RE_project/Data_all_RH-RE/GitHub_repo/RH-RE_scanning/notebooks")
if(!file.exists(file.path("..", "data", "meanF", "meanF_data.rda"))) {
#### need to update file paths once we find a permanent place to store the data
untar(file.path("..", "data", "meanF", "meanF_NovaSeq_data.tar.gz"),
exdir = file.path("..", "data", "meanF"))
datafiles <- untar(file.path("..", "data", "meanF", "meanF_NovaSeq_data.tar.gz"), list = TRUE)
meanF_data <- list()
for(i in 1:length(datafiles)) {
# read mean fluorescence data for variants detected in binned sort experiment
if(grepl("DMS_meanF", datafiles[i])) {
rep <- str_extract(datafiles[i], "rep.")
meanF_data[[rep]] <- read.csv(file.path("..", "data", "meanF", datafiles[i]),
stringsAsFactors = TRUE)
# add column for total cell count
meanF_data[[rep]] <- meanF_data[[rep]] %>%
mutate(cellCount_total = cellCount_b1 + cellCount_b2 + cellCount_b3 + cellCount_b4)
# add columns for protein background and RE
meanF_data[[rep]] <- meanF_data[[rep]] %>%
separate(REBC, into = c("bg", "RE"), sep = "_", remove = F, extra = "merge") %>%
mutate(bg = str_replace(factor(bg), "^SR", "AncSR"),
RE = str_replace(RE, "REBC\\d+", as.character(REBC_to_RE(RE))))
# sort rows by REBC and AA_var
meanF_data[[rep]] <- meanF_data[[rep]] %>% arrange(REBC, AA_var)
}
# read in data from debulk sort experiment
else if(grepl("Debulk", datafiles[i])) {
debulk_data <- read.csv(file.path("..", "data", "meanF", datafiles[i]),
stringsAsFactors = TRUE)
}
}
# unlist meanF data and calculate current SE(meanF) per variant and REBC
meanF_data <- rbind(meanF_data$rep1, meanF_data$rep2, meanF_data$rep3, meanF_data$rep4) %>%
group_by(AA_var,REBC) %>%
# Re-organize the dataframe: each row is a variant-REBC combo
summarise(avg_meanF = mean(meanF,na.rm = T), # meanF per var-REBC across replicates
n_reps = n(), # number of replicates in which var-REBC is found
sd_meanF = sd(meanF,na.rm = T),
se_meanF = sd_meanF / sqrt(n_reps), # standard error of average meanF
mean_read_count = mean(Count_total,na.rm = T), # mean read count
min_read_count = min(Count_total,na.rm = T)) %>% # minimum value of read count across reps
# Add info of rep 1: read count, meanF
full_join(.,meanF_data$rep1,by=c("AA_var","REBC")) %>%
dplyr::select(AA_var,REBC,cellCount_total,avg_meanF,n_reps,sd_meanF,se_meanF,mean_read_count,min_read_count,meanF,Count_total) %>%
dplyr::rename(meanF_REP1 = meanF, RC_REP1 = Count_total) %>%
# Add info of rep 2: read count, meanF
full_join(.,meanF_data$rep2,by=c("AA_var","REBC")) %>%
dplyr::select(AA_var,REBC,cellCount_total,avg_meanF,n_reps,sd_meanF,se_meanF,mean_read_count,min_read_count,
meanF_REP1,RC_REP1,meanF,Count_total) %>%
dplyr::rename(meanF_REP2 = meanF, RC_REP2 = Count_total) %>%
# Add info of rep 3: read count, meanF
full_join(.,meanF_data$rep3,by=c("AA_var","REBC")) %>%
dplyr::select(AA_var,REBC,cellCount_total,avg_meanF,n_reps,sd_meanF,se_meanF,mean_read_count,min_read_count,
meanF_REP1,RC_REP1,meanF_REP2,RC_REP2,meanF,Count_total) %>% dplyr::rename(meanF_REP3 = meanF, RC_REP3= Count_total) %>%
# Add info of rep 4: read count, meanF
full_join(.,meanF_data$rep4,by=c("AA_var","REBC")) %>%
dplyr::select(AA_var,REBC,cellCount_total,avg_meanF,n_reps,sd_meanF,se_meanF,mean_read_count,min_read_count,
meanF_REP1,RC_REP1,meanF_REP2,RC_REP2,meanF_REP3,RC_REP3,meanF,Count_total) %>%
dplyr::rename(meanF_REP4 = meanF, RC_REP4 = Count_total) %>%
mutate(v = paste(AA_var,REBC,sep="_"), # create 'v' variable (useful later)
type = ifelse(grepl(paste(c("minilib","SRE","ERE"),collapse = "|"),REBC), "control","exp")) # mark rows as "controls" or "experiments"
# save data files for faster loading
save(meanF_data, file = file.path("..", "data", "meanF", "meanF_data.rda"))
save(debulk_data, file = file.path("..", "data", "meanF", "debulk_data.rda"))
} else {
# load R data frames if already created
load(file.path("..", "data", "meanF", "meanF_data.rda"))
load(file.path("..", "data", "meanF", "debulk_data.rda"))
}
rlang::last_error()
untar(file.path("..", "data", "meanF", "meanF_NovaSeq_data.tar.gz"),
exdir = file.path("..", "data", "meanF"))
datafiles <- untar(file.path("..", "data", "meanF", "meanF_NovaSeq_data.tar.gz"), list = TRUE)
datafiles
grepl("^DMS_meanF", datafiles[1])
for(i in 1:length(datafiles)) {
# read mean fluorescence data for variants detected in binned sort experiment
if(grepl("DMS_meanF", datafiles[i])) {
rep <- str_extract(datafiles[i], "rep.")
meanF_data[[rep]] <- read.csv(file.path("..", "data", "meanF", datafiles[i]),
stringsAsFactors = TRUE)
# add column for total cell count
meanF_data[[rep]] <- meanF_data[[rep]] %>%
mutate(cellCount_total = cellCount_b1 + cellCount_b2 + cellCount_b3 + cellCount_b4)
# add columns for protein background and RE
meanF_data[[rep]] <- meanF_data[[rep]] %>%
separate(REBC, into = c("bg", "RE"), sep = "_", remove = F, extra = "merge") %>%
mutate(bg = str_replace(factor(bg), "^SR", "AncSR"),
RE = str_replace(RE, "REBC\\d+", as.character(REBC_to_RE(RE))))
# sort rows by REBC and AA_var
meanF_data[[rep]] <- meanF_data[[rep]] %>% arrange(REBC, AA_var)
}
# read in data from debulk sort experiment
else if(grepl("Debulk", datafiles[i])) {
debulk_data <- read.csv(file.path("..", "data", "meanF", datafiles[i]),
stringsAsFactors = TRUE)
}
}
meanF_data <- readr::read_csv("/Users/santiagoherrera/Desktop/UChicago/Thornton_LAB/RH-RE_project/Data_all_RH-RE/Library_sequencing/NovaSeq/Analysis/meanF_data_NovaSeq.csv.gz")
# check for packages and install any that are missing
packages <- c("tidyr", "MASS", "ggplot2", "Matrix", "stringr", "tibble",
"patchwork", "foreach", "doParallel", "ggpubr",
"splines2","matrixStats", "forcats", "dplyr")
invisible(lapply(packages, library, character.only=TRUE))
head(meanF_data)
# How much data is retained after filtering by standard error
meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc) %>% mutate(included = ifelse(se_meanF>0.1,"out","in")) %>%
group_by(included) %>% summarise(n=n(),mean_se = mean(se_meanF)) %>% mutate(prop=n/sum(n))
rc <- 24
# How much data is retained after filtering by standard error
meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc) %>% mutate(included = ifelse(se_meanF>0.1,"out","in")) %>%
group_by(included) %>% summarise(n=n(),mean_se = mean(se_meanF)) %>% mutate(prop=n/sum(n))
## REP1-2
a <- meanF_data %>% filter(Count_total_REP1 >= rc & Count_total_REP2 >= rc) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP1,z=se_meanF)) +
stat_summary_2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep1") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis(option = "B",begin=0,end=1) +
guides(fill=guide_legend(title="SE(meanF)")) + ggtitle("Reps 1-2") # points colored by SE(meanF)
b <- meanF_data %>% filter(Count_total_REP1 >= rc & Count_total_REP2 >= rc) %>% ggplot(aes(x = se_meanF)) +
geom_histogram(aes(y=..count../sum(..count..)),bins = 100,color="black",fill="gray") +
theme_classic() + xlab("SE(meanF)") + ylab("Percent of variants") +
geom_vline(xintercept = 0.1,col="gray") + scale_y_continuous(labels = scales::percent) +
annotate(geom = "text", x = 0.35, y = 0.04, label="Removed variants: 2.4%") # histogram of SE(meanF)
c <- meanF_data %>% filter(Count_total_REP1 >= rc & Count_total_REP2 >= rc & se_meanF <= 0.1) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP1)) +
stat_bin2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep1") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis() + theme(legend.position = "none")
## REP2-3
d <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP3 >= rc) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP3,z=se_meanF)) +
stat_summary_2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep3") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis(option = "B",begin=0,end=1) +
guides(fill=guide_legend(title="SE(meanF)")) + ggtitle("Reps 2-3")
e <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP3 >= rc) %>% ggplot(aes(x = se_meanF)) +
geom_histogram(aes(y=..count../sum(..count..)),bins = 100,color="black",fill="gray") +
theme_classic() + xlab("SE(meanF)") + ylab("Percent of variants") +
geom_vline(xintercept = 0.1,col="gray") + scale_y_continuous(labels = scales::percent) +
annotate(geom = "text", x = 0.35, y = 0.04, label="Removed variants: 2.91%") # histogram of SE(meanF)
f <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP3 >= rc & se_meanF <= 0.1) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP3)) +
stat_bin2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep3") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis() + theme(legend.position = "none")
## REP2-4
g <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP4,z=se_meanF)) +
stat_summary_2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep4") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis(option = "B",begin=0,end=1) +
guides(fill=guide_legend(title="SE(meanF)")) + ggtitle("Reps 2-4")
h <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc) %>% ggplot(aes(x = se_meanF)) +
geom_histogram(aes(y=..count../sum(..count..)),bins = 100,color="black",fill="gray") +
theme_classic() + xlab("SE(meanF)") + ylab("Percent of variants") +
geom_vline(xintercept = 0.1,col="gray") + scale_y_continuous(labels = scales::percent) +
annotate(geom = "text", x = 0.35, y = 0.04, label="Removed variants: 3.21%") # histogram of SE(meanF)
i <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc & se_meanF <= 0.1) %>% ggplot(aes(x=meanF_REP2,y=meanF_REP4)) +
stat_bin2d(bins = 90) + theme_classic() + xlab("meanF, rep2") + ylab("meanF, rep4") +
geom_abline(slope = 1,intercept = 0,col="gray") + viridis::scale_fill_viridis() + theme(legend.position = "none")
(a + b + c) / (d + e + f) / (g + h + i)
r12 <- meanF_data %>% filter(Count_total_REP1 >= rc & Count_total_REP2 >= rc & se_meanF <= 0.1) %>%
select(AA_var,REBC,avg_meanF,meanF_REP1,meanF_REP2)
r23 <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP3 >= rc  & se_meanF <= 0.1) %>%
select(AA_var,REBC,avg_meanF,meanF_REP2,meanF_REP3)
r24 <- meanF_data %>% filter(Count_total_REP2 >= rc & Count_total_REP4 >= rc & se_meanF <= 0.1) %>%
select(AA_var,REBC,avg_meanF,meanF_REP2,meanF_REP4)
knots_r12 <- summary(r12$meanF_REP1)[3] #using the median meanF of rep1 as internal knot
bound_knots_r12 <- c(min(c(meanF_data$meanF_REP1,meanF_data$meanF_REP2),na.rm = T), max(c(meanF_data$meanF_REP1,meanF_data$meanF_REP2),na.rm = T)) # boundary knots
degree <- 2 # degree of piecewise polynomials
# Create the basis matrix for the I-spline:
basis_mat12 <- iSpline(r12$meanF_REP1, knots = knots_r12, Boundary.knots = bound_knots_r12, degree = degree)
# Fit a linear regression model to the second replicate using the basis matrix as predictors:
spline_r12 <- lm(r12$meanF_REP2 ~ basis_mat12)
print("REPS: 1 and 2")
print(paste("Correlation before correction:", cor(r12$meanF_REP1,r12$meanF_REP2)))
print(paste("Correlation of the 'active' region before correction:", cor(r12[r12$avg_meanF>=-4,]$meanF_REP1,r12[r12$avg_meanF>=-4,]$meanF_REP2)))
print(paste("Correlation after correction:", cor(r12$meanF_REP1_c,r12$meanF_REP2)))
# Correct rep1 values using I-Spline models: Predict the values of the rep1 using the fitted model and the basis matrix.
# The 'predict' function generates a new basis matrix based on the fitted basis matrix and the new data.
# The new basis matrix is multiplied by the spline coefficients to get the new X's (and then add the intercept)
r12$meanF_REP1_c <- (predict(basis_mat12, newx = r12$meanF_REP1) %*% coef(spline_r12)[-1]) + coef(spline_r12)[1]
print(paste("Correlation after correction:", cor(r12$meanF_REP1_c,r12$meanF_REP2)))
print(paste("Correlation of the 'active' region after correction:", cor(r12[r12$avg_meanF>=-4,]$meanF_REP1_c,r12[r12$avg_meanF>=-4,]$meanF_REP2)))
knots_r23 <- summary(r23$meanF_REP3)[3] #using the median meanF of rep3 as internal knot
bound_knots_r23 <- c(min(c(meanF_data$meanF_REP2,meanF_data$meanF_REP3),na.rm = T), max(c(meanF_data$meanF_REP2,meanF_data$meanF_REP3),na.rm = T)) # boundary knots
degree <- 2 # degree of piecewise polynomials
basis_mat23 <- iSpline(r23$meanF_REP3, knots = knots_r23, Boundary.knots = bound_knots_r23, degree = degree)
spline_r23 <- lm(r23$meanF_REP2 ~ basis_mat23)
r23$meanF_REP3_c <- (predict(basis_mat23, newx = r23$meanF_REP3) %*% coef(spline_r23)[-1]) + coef(spline_r23)[1]
print("REPS: 2 and 3")
print(paste("Correlation before correction:", cor(r23$meanF_REP2,r23$meanF_REP3)))
print(paste("Correlation of the 'active' region before correction:", cor(r23[r23$avg_meanF>=-4,]$meanF_REP2,r23[r23$avg_meanF>=-4,]$meanF_REP3)))
print(paste("Correlation after correction:", cor(r23$meanF_REP2,r23$meanF_REP3_c)))
print(paste("Correlation of the 'active' region after correction:", cor(r23[r23$avg_meanF>=-4,]$meanF_REP2,r23[r23$avg_meanF>=-4,]$meanF_REP3_c)))
knots_r24 <- -4.6#summary(r24$meanF_REP4)[1] #using the median meanF of rep4 as internal knot
bound_knots_r24 <- c(min(c(meanF_data$meanF_REP2,meanF_data$meanF_REP4),na.rm = T), max(c(meanF_data$meanF_REP2,meanF_data$meanF_REP4),na.rm = T)) # boundary knots
degree <- 2 # degree of piecewise polynomials
basis_mat24 <- iSpline(r24$meanF_REP4, knots = knots_r24, Boundary.knots = bound_knots_r24, degree = degree)
spline_r24 <- lm(r24$meanF_REP2 ~ basis_mat24)
r24$meanF_REP4_c <- (predict(basis_mat24, newx = r24$meanF_REP4) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1]
print("REPS: 2 and 4")
print(paste("Correlation before correction:", cor(r24$meanF_REP2,r24$meanF_REP4)))
print(paste("Correlation of the 'active' region before correction:", cor(r24[r24$avg_meanF>=-4,]$meanF_REP2,r24[r24$avg_meanF>=-4,]$meanF_REP4)))
print(paste("Correlation after correction:", cor(r24$meanF_REP2,r24$meanF_REP4_c)))
print(paste("Correlation of the 'active' region after correction:", cor(r24[r24$avg_meanF>=-4,]$meanF_REP2,r24[r24$avg_meanF>=-4,]$meanF_REP4_c)))
rep2 <- meanF_data %>% filter(Count_total_REP2 >= rc) %>%
select(AA_var,REBC,bg,RE,meanF_REP2,type) %>% rename(meanF = meanF_REP2) %>% mutate(REP = "REP2") # all rep2 variants
rep1 <- meanF_data %>% filter(Count_total_REP1 >= rc) %>%
select(AA_var,REBC,bg,RE,meanF_REP1,type) %>% mutate(REP = "REP1") # all rep1 variants
rep3 <- meanF_data %>% filter(Count_total_REP3 >= rc) %>%
select(AA_var,REBC,bg,RE,meanF_REP3,type) %>% mutate(REP = "REP3") # all rep3 variants
rep4 <- meanF_data %>% filter(Count_total_REP4 >= rc ) %>%
select(AA_var,REBC,bg,RE,meanF_REP4,type) %>% rename(meanF = meanF_REP4) %>% mutate(REP = "REP4") # all rep4 variants
rep4_ctls <- meanF_data %>% filter(Count_total_REP4 >= rc & type== "control") %>%
filter(AA_var %in% c("GSKV","EGKA","GGKM")) %>% select(AA_var,REBC,bg,RE,meanF_REP4,type) %>% rename(meanF = meanF_REP4) %>%
mutate(REP = "REP4")
rep4 <- unique(rbind(rep4,rep4_ctls)) # manually include isogenic controls (make sure they're not discarded)
rep1 <- rep1 %>% mutate(meanF_REP1_c = ((predict(basis_mat12, newx = rep1$meanF_REP1) %*% coef(spline_r12)[-1]) + coef(spline_r12)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_REP1_c,type,REP) %>% rename(meanF = meanF_REP1_c)
rep3 <- rep3 %>% mutate(meanF_REP3_c = ((predict(basis_mat23, newx = rep3$meanF_REP3) %*% coef(spline_r23)[-1]) + coef(spline_r23)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_REP3_c,type,REP) %>% rename(meanF = meanF_REP3_c)
rep4_c_ctls <- rep4 %>% mutate(meanF_REP4_c = ((predict(basis_mat24, newx = rep4$meanF_REP4) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_REP4_c,type,REP) %>% rename(meanF_c = meanF_REP4_c) %>% filter(type=="control" & AA_var %in% c("GSKV","EGKA","GGKM"))
rep4_ctls
# Compare uncorrected vs corrected meanF values for isogenic controls in Rep4
# Correct controls:
rep4_c_ctls <- rep4_ctls %>% mutate(meanF_c = ((predict(basis_mat24, newx = rep4$meanF_REP4) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_REP4_c,type,REP)
rep4_ctls %>% mutate(meanF_c = ((predict(basis_mat24, newx = rep4$meanF_REP4) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_c,type,REP)
# Compare uncorrected vs corrected meanF values for isogenic controls in Rep4
# Correct controls:
rep4_c_ctls <- rep4_ctls %>% mutate(meanF_c = ((predict(basis_mat24, newx = rep4_ctls$meanF) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,meanF_c,type,REP)
rep4_c_ctls
rep4_ctls %>% mutate(meanF_c = ((predict(basis_mat24, newx = rep4_ctls$meanF) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,type,REP,meanF,meanF_c)
# Re-calculate SE(meanF) of variants after correction.
meanF_data_corrected <- rbind(rep1,rep2,rep3,rep4) %>%
pivot_wider(names_from = REP, values_from = meanF) %>%
mutate(avg_meanF = rowMeans(.[6:9],na.rm = T), # meanF per var-REBC across replicates
n_reps = rowSums(!is.na(.[6:9])), # number of replicates in which var-REBC is found
sd_meanF = rowSds(as.matrix(.[6:9]),na.rm=TRUE),
se_meanF = sd_meanF / sqrt(n_reps)) # standard error of average meanF
# Proportions of variants kepts and discarded based on SE(meanF) cutoff
meanF_data_corrected %>% filter(n_reps != 1) %>% mutate(included = ifelse(se_meanF>0.1,"out","in")) %>%
group_by(included) %>% summarise(n=n(),mean_se = mean(se_meanF)) %>% mutate(prop=n/sum(n))
# New corrected dataset
ctls <- meanF_data_corrected %>% filter(type=="control") %>%
filter(grepl(paste(c("GSKV","EGKA","GGKM"),collapse = "|"),AA_var)) # Extract control variants, and filter out sequencing errors in controls
meanF_data_corrected <- meanF_data_corrected %>% filter(se_meanF <= 0.1)
meanF_data_corrected <- unique(rbind(meanF_data_corrected,ctls)) # Manually add controls to new dataset
# Plot meanF of control variants (from Rep1 and Rep4)
#### TODO: need to include data from Reps 2 and 3
bounds <- meanF_data_corrected %>% mutate(group=ifelse(grepl("[*]",AA_var),"null","other")) %>%
group_by(group) %>% summarise(min = min(avg_meanF), mean = mean(avg_meanF), max= max(avg_meanF))
bounds
head(meanF_data_corrected)
colnames(meanF_data)
colnames(meanF_data_corrected)
ctls_in_lib <- meanF_data_corrected %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE_lib",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE_lib",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE_lib",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE_lib",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE_lib"))
ctls_in_lib
ctls_in_lib <- meanF_data_corrected %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE_lib",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE_lib",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE_lib",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE_lib",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE_lib")) %>% select(AA_var,REBC,avg_meanF,REP) %>% rename(meanF = avg_meanF)
ctls_in_lib
ctl_rep4
ctl_rep1 <- ctls %>% filter(!is.na(REP1)) %>% select(AA_var,REBC,REP1) %>% mutate(REP = "REP1") %>% rename(meanF = REP1)
ctl_rep4 <- ctls %>% filter(!is.na(REP4)) %>% select(AA_var,REBC,REP4) %>% mutate(REP = "REP4") %>% rename(meanF = REP4)
ctl_rep4
ctls_in_lib <- meanF_data_corrected %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = "Library",
Variant = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE_lib",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE_lib",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE_lib",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE_lib",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE_lib")) %>% select(AA_var,REBC,avg_meanF,REP,Variant) %>% rename(meanF = avg_meanF)
ctls_in_lib
ctl_rep1 <- ctls %>% filter(!is.na(REP1)) %>% select(AA_var,REBC,REP1) %>% mutate(REP = "REP1",Variant=NA) %>% rename(meanF = REP1)
ctl_rep4 <- ctls %>% filter(!is.na(REP4)) %>% select(AA_var,REBC,REP4) %>% mutate(REP = "REP4",Variant=NA) %>% rename(meanF = REP4)
ctl_rep1
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP,shape=Variant)) +
scale_fill_manual(values = c("#edd221","#2651a6")) +
ylim(c(-4.7,-2)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$min[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP,shape=Variant)) +
scale_fill_manual(values = c("#edd221","#2651a6","black")) +
ylim(c(-4.7,-2)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$min[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP,shape=Variant)) +
scale_fill_manual(values = c("black","#edd221","#2651a6")) +
ylim(c(-4.7,-2)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$min[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
ctl_rep1 <- ctls %>% filter(!is.na(REP1)) %>% select(AA_var,REBC,REP1) %>% mutate(REP = "REP1") %>% rename(meanF = REP1)
ctl_rep4 <- ctls %>% filter(!is.na(REP4)) %>% select(AA_var,REBC,REP4) %>% mutate(REP = "REP4") %>% rename(meanF = REP4)
ctls_in_lib <- meanF_data_corrected %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = "Library",
Variant = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE")) %>%
select(AA_var,Variant,avg_meanF,REP) %>% rename(meanF = avg_meanF, REBC = Variant)
ctl_rep1
ctls_in_lib
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP)) +
scale_fill_manual(values = c("black","#edd221","#2651a6")) +
ylim(c(-4.7,-2)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$min[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
ctls_in_lib <- meanF_data_corrected %>% filter(type=="control") %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = "Library",
Variant = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE")) %>%
select(AA_var,Variant,avg_meanF,REP) %>% rename(meanF = avg_meanF, REBC = Variant)
ctls_in_lib
ctls_in_lib <- meanF_data_corrected %>% mutate(v = paste(AA_var,REBC,sep = "_")) %>%
filter(v %in% c("EGKA_AncSR1_REBC3","EGKA_AncSR2_REBC3","GGKM_AncSR1_REBC3","GGKM_AncSR2_REBC1","GSKV_AncSR2_REBC1")) %>%
mutate(REP = "Library",
Variant = case_when(v == "EGKA_AncSR1_REBC3" ~ "AncSR1_ERE",
v == "EGKA_AncSR2_REBC3" ~ "AncSR2_rh_ERE",
v == "GGKM_AncSR1_REBC3" ~ "AncSR1_GGKM_ERE",
v == "GGKM_AncSR2_REBC1" ~ "AncSR2_GGKM_SRE",
v == "GSKV_AncSR2_REBC1" ~ "AncSR2_SRE")) %>%
select(AA_var,Variant,avg_meanF,REP) %>% rename(meanF = avg_meanF, REBC = Variant)
ctls_in_lib
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP)) +
scale_fill_manual(values = c("black","#edd221","#2651a6")) +
ylim(c(-4.7,-2.5)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$min[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
# Compare uncorrected vs corrected meanF values for isogenic controls in Rep4
# Given the overshoot of the I-spline, all estimated values are pulled towards lower predicted values of meanF (compare 'meanF' vs 'meanF_c' columns). The effect is especially severe for AncSR2_SRE and AncSR1_GGKM_ERE. These variants are active based on cytometry data from isogenic strains, but are predicted as null variants (see plot below showing the lower and upper bounds of detection).
rep4_ctls %>% mutate(meanF_c = ((predict(basis_mat24, newx = rep4_ctls$meanF) %*% coef(spline_r24)[-1]) + coef(spline_r24)[1])[,1]) %>% select(AA_var,REBC,bg,RE,type,REP,meanF,meanF_c)
rbind(ctl_rep1,ctl_rep4,ctls_in_lib) %>%
ggplot(aes(x=REBC,y=meanF)) +
geom_point(color="black",pch = 21,size=2.5, aes(fill=REP)) +
scale_fill_manual(values = c("black","#edd221","#2651a6")) +
ylim(c(-4.7,-2.5)) +
theme_bw() + coord_flip() +
theme(axis.title.x = element_text(size=12,face="bold"),
axis.text.x = element_text(size=10),
axis.text.y = element_text(size = 10),
axis.title=element_text(size=12,face="bold")) +
geom_hline(yintercept = bounds$mean[1], size=1, linetype="dashed",col="red") +
geom_hline(yintercept = bounds$max[2], size=1, linetype="dashed",col="red") +
ylab("Fluorescence")
p.fix <- function(s,N){(1-exp(-2*s))/(1-exp(-2*N*s))}
N <- 10000
sij <- 0.01
sik <- 0.03
sil <- -0.05
pij <- p.fix(sij,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pik <- p.fix(sik,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pil <- p.fix(sil,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pij
pik
pil
sil <- -0.00005
pil <- p.fix(sil,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pil
pij <- p.fix(sij,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pik <- p.fix(sik,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pil <- p.fix(sil,N)/sum(p.fix(sij,N),p.fix(sik,N),p.fix(sil,N))
pij
pik
pil
sij/sum(sij,sik,sil)
sik/sum(sij,sik,sil)
sil/sum(sij,sik,sil)
